{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from utils import CustomDataset, train, train_with_int_input\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Doc2idxs as input"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available(): # in my case it means running in colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    from pathlib import Path\n",
    "    sources_path = Path(\"/content/drive/MyDrive/Data\")\n",
    "    X_train = np.load(str(sources_path / 'doc2idxs_X_train.npy'))\n",
    "    y_train = np.load(str(sources_path / 'y_train.npy'))\n",
    "    X_test = np.load(str(sources_path / 'doc2idxs_X_test.npy'))\n",
    "    y_test = np.load(str(sources_path / 'y_test.npy'))\n",
    "\n",
    "    saving_path=str(sources_path / 'GRU_doc2idxs.pth')\n",
    "else:\n",
    "    X_train = np.load('Data/doc2idxs_X_train.npy')\n",
    "    y_train = np.load('Data/y_train.npy')\n",
    "    X_test = np.load('Data/doc2idxs_X_test.npy')\n",
    "    y_test = np.load('Data/y_test.npy')\n",
    "\n",
    "    saving_path='Trained_models/GRU_doc2idxs.pth'\n",
    "\n",
    "train_df = CustomDataset(X_train, y_train)\n",
    "test_df = CustomDataset(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class GRU_doc2idxs(nn.Module):\n",
    "    def __init__(self,voc_size, embedding_size, padding_idx, hidden_state_size, n_rec_layers, output_size):\n",
    "        super().__init__()\n",
    "        self.n_rec_layers = n_rec_layers\n",
    "        self.hidden_state_size = hidden_state_size\n",
    "\n",
    "        self.embedding = nn.Embedding(voc_size, embedding_size, padding_idx)\n",
    "        self.gru = nn.GRU(embedding_size, hidden_state_size, n_rec_layers, batch_first=True, dropout=0.3)\n",
    "        self.bn = nn.BatchNorm1d(hidden_state_size)\n",
    "        self.fc = nn.Linear(hidden_state_size, output_size)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        h_0 = torch.zeros(self.n_rec_layers, X.size(0), self.hidden_state_size).to(device)\n",
    "\n",
    "        X, _ = self.gru(X, h_0)\n",
    "        X = X[:, -1:, :].flatten(start_dim=1)\n",
    "        X = self.bn(X)\n",
    "        X = F.relu(X)\n",
    "        X = self.fc(X)\n",
    "        X = self.logsoftmax(X)\n",
    "\n",
    "        return X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gru = GRU_doc2idxs(\n",
    "    voc_size=36879, # from Pre-processing.ipynb\n",
    "    embedding_size=512,\n",
    "    padding_idx=0, # from Pre-processing.ipynb\n",
    "    hidden_state_size=512,\n",
    "    n_rec_layers=1,\n",
    "    output_size=5\n",
    ").to(device)\n",
    "\n",
    "optimizer = Adam(gru.parameters(), lr=1e-4),\n",
    "\n",
    "train_with_int_input(gru,\n",
    "      optimizer=optimizer,\n",
    "      train_loader=DataLoader(train_df, batch_size=256, shuffle=True),\n",
    "      test_loader=DataLoader(test_df, batch_size=256, shuffle=False),\n",
    "      epochs=45,\n",
    "      saving_path=saving_path,\n",
    "      scheduler=StepLR(optimizer, step_size=1, gamma=0.99))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = torch.argmax(gru(torch.from_numpy(X_test).to(device)), dim=1).cpu().numpy() - 2\n",
    "    print(y_pred)\n",
    "    print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Doc2matrix input"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available(): # in my case it means running in colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    from pathlib import Path\n",
    "    sources_path = Path(\"/content/drive/MyDrive/Data\")\n",
    "    X_train = np.load(str(sources_path / 'doc2matrix_X_train.npy'))\n",
    "    y_train = np.load(str(sources_path / 'y_train.npy'))\n",
    "    X_test = np.load(str(sources_path / 'doc2matrix_X_test.npy'))\n",
    "    y_test = np.load(str(sources_path / 'y_test.npy'))\n",
    "\n",
    "    saving_path=str(sources_path / 'GRU_doc2matrix.pth')\n",
    "else:\n",
    "    X_train = np.load('Data/doc2matrix_X_train.npy')\n",
    "    y_train = np.load('Data/y_train.npy')\n",
    "    X_test = np.load('Data/doc2matrix_X_test.npy')\n",
    "    y_test = np.load('Data/y_test.npy')\n",
    "\n",
    "    saving_path='Trained_models/GRU_doc2matrix.pth'\n",
    "\n",
    "train_df = CustomDataset(X_train, y_train)\n",
    "test_df = CustomDataset(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class GRU_doc2matrix(nn.Module):\n",
    "    def __init__(self, hidden_state_size, n_rec_layers, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.n_rec_layers = n_rec_layers\n",
    "        self.hidden_state_size = hidden_state_size\n",
    "\n",
    "        self.gru = nn.GRU(input_size, hidden_state_size, n_rec_layers, batch_first=True, dropout=0.3)\n",
    "        self.bn = nn.BatchNorm1d(hidden_state_size)\n",
    "        self.fc = nn.Linear(hidden_state_size, output_size)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        h_0 = torch.zeros(self.n_rec_layers, X.size(0), self.hidden_state_size).to(device)\n",
    "\n",
    "        X, _ = self.gru(X, h_0)\n",
    "        X = X[:, -1:, :].flatten(start_dim=1)\n",
    "        X = self.bn(X)\n",
    "        X = F.relu(X)\n",
    "        X = self.fc(X)\n",
    "        X = self.logsoftmax(X)\n",
    "\n",
    "        return X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/45 [00:09<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 10, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 10 elements not 512",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 11\u001B[0m\n\u001B[1;32m      1\u001B[0m gru \u001B[38;5;241m=\u001B[39m GRU(\n\u001B[1;32m      2\u001B[0m     voc_size\u001B[38;5;241m=\u001B[39mvoc_size,\n\u001B[1;32m      3\u001B[0m     embedding_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m512\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      7\u001B[0m     output_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m\n\u001B[1;32m      8\u001B[0m )\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     10\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m Adam(gru\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-4\u001B[39m)\n\u001B[0;32m---> 11\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgru\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m      \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m45\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m      \u001B[49m\u001B[43msaving_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mTrained_models/GRU.pth\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[16], line 41\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, optimizer, train_loader, test_loader, epochs, saving_path, scheduler)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m X, y \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28miter\u001B[39m(train_loader):\n\u001B[1;32m     40\u001B[0m     X, y \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mto(device), y\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m---> 41\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(y_pred, y)\n\u001B[1;32m     43\u001B[0m     train_loss_sum \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/sentiment/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[0;32mIn[23], line 20\u001B[0m, in \u001B[0;36mGRU.forward\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m     18\u001B[0m X \u001B[38;5;241m=\u001B[39m X[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m10\u001B[39m:, :]\u001B[38;5;241m.\u001B[39msqueeze(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(X\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m---> 20\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m X \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(X)\n\u001B[1;32m     22\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc(X)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/sentiment/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/sentiment/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:168\u001B[0m, in \u001B[0;36m_BatchNorm.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    161\u001B[0m     bn_training \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_mean \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_var \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    163\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001B[39;00m\n\u001B[1;32m    165\u001B[0m \u001B[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001B[39;00m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001B[39;00m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m--> 168\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001B[39;49;00m\n\u001B[1;32m    171\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunning_mean\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrack_running_stats\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunning_var\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrack_running_stats\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbn_training\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexponential_average_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/sentiment/lib/python3.10/site-packages/torch/nn/functional.py:2438\u001B[0m, in \u001B[0;36mbatch_norm\u001B[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001B[0m\n\u001B[1;32m   2435\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m training:\n\u001B[1;32m   2436\u001B[0m     _verify_batch_size(\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize())\n\u001B[0;32m-> 2438\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2439\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrunning_mean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrunning_var\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmomentum\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackends\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcudnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menabled\u001B[49m\n\u001B[1;32m   2440\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: running_mean should contain 10 elements not 512"
     ]
    }
   ],
   "source": [
    "gru = GRU_doc2matrix(\n",
    "    hidden_state_size=512,\n",
    "    n_rec_layers=2,\n",
    "    input_size=200,\n",
    "    output_size=5\n",
    ").to(device)\n",
    "\n",
    "optimizer = Adam(gru.parameters(), lr=1e-4)\n",
    "\n",
    "train(gru,\n",
    "      optimizer,\n",
    "      train_loader=DataLoader(train_df, batch_size=256, shuffle=True),\n",
    "      test_loader=DataLoader(test_df, batch_size=256, shuffle=False),\n",
    "      epochs=45,\n",
    "      saving_path=saving_path,\n",
    "      scheduler=StepLR(optimizer, step_size=1, gamma=0.99))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  1 ... -1 -1  0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.49      0.73      0.58       473\n",
      "          -1       0.64      0.69      0.67      2746\n",
      "           0       0.82      0.65      0.72      4174\n",
      "           1       0.46      0.75      0.57       522\n",
      "           2       0.45      0.79      0.58       105\n",
      "\n",
      "    accuracy                           0.68      8020\n",
      "   macro avg       0.57      0.72      0.62      8020\n",
      "weighted avg       0.71      0.68      0.68      8020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = torch.argmax(gru(torch.from_numpy(X_test).to(device)), dim=1).cpu().numpy() - 2\n",
    "    print(y_pred)\n",
    "    print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
